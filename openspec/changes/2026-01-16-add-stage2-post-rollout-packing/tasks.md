## 1. Implementation (vLLM rollout backend + post-rollout packing + batched rollouts)
- [x] 1.1 Add YAML knobs under `custom.extra.rollout_matching`:
  - [x] `rollout_backend` (default `"vllm"`, allowed: `"vllm"|"hf"`)
  - [x] `vllm` (mapping) - rollout-only vLLM engine knobs (colocate only):
    - [x] `tensor_parallel_size` (default 4 on 4-GPU runs)
    - [x] `gpu_memory_utilization` (default **0.45** as a conservative starting point)
    - [x] `max_model_len` (required; should cover prompt_len + max_new_tokens)
    - [x] `enable_lora` (required for on-policy LoRA sync)
    - [x] `enable_prefix_caching` (optional; default true)
    - [x] `sleep_level` (optional; default 0; only for emergency memory relief)
  - [x] `rollout_generate_batch_size` (default 1) - per-rank batch size for rollout `generate()` calls
  - [x] (no extra packing knobs) stage_2 packing is enabled/disabled via existing `training.packing` config only.
- [x] 1.2 Update `src/sft.py`:
  - [x] Remove/relax the fail-fast that rejects `training.packing: true` for `rollout_matching_sft`
  - [x] When `trainer_variant=rollout_matching_sft` and packing is enabled:
    - [x] DO NOT wrap the dataset with `build_packed_dataset` (dynamic packing happens inside trainer)
    - [x] DO NOT force `per_device_train_batch_size=1` (trainer will pack the forward pass to `bsz=1`)
    - [x] propagate packing config (length/buffer/min_fill/drop_last) into trainer config injection
  - [x] Ensure rollout-matching still uses identity collator and `remove_unused_columns=false`
- [x] 1.3 Update `src/trainers/rollout_matching_sft.py`:
  - [x] Add a rollout-backend abstraction:
    - [x] HF backend: current generate path (with `_rollout_many` microbatching)
    - [x] vLLM backend (default): ms-swift-style colocate engine returning `response_token_ids` + `prompt_token_ids`
      - [x] enforce colocate-only; explicitly reject server mode for this trainer
      - [x] enforce TP=4 in typical 4-GPU runs (and validate `world_size % tp == 0`)
      - [x] use TP-group gather/slice pattern for TP>1 (single engine infer per TP group)
      - [x] encode prompts with `template.mode="vllm"` so multimodal payload is attached
      - [x] weight sync policy (on-policy, LoRA-only):
        - [x] base sync once (step 0 / resume)
        - [x] adapter sync on `global_step` boundaries (not per grad-acc micro-step)
        - [x] require `vllm.enable_lora: true` when backend=vllm
      - [x] fail-fast on vLLM errors/OOM (no automatic fallback); allow explicit YAML `rollout_backend: hf`
  - [x] Add a context manager to temporarily disable `template.padding_free` and `template.packing` during rollout generation
  - [x] Implement `_rollout_many(...)` microbatched generation (padded batch)
  - [x] Implement dynamic post-rollout packing (carry-only):
    - [x] maintain a rank-local buffer of `(encoded, meta)` segments
    - [x] select a subset per step such that `sum(encoded_len) <= packing_length`, maximizing fill best-effort
    - [x] never split a segment; carry leftovers to next step
    - [x] enforce `packing_drop_last: true` for carry-only mode (fail fast if false)
    - [x] enforce `packing_buffer` as a hard cap (fail fast if buffer grows beyond the cap; suggest reducing raw batch size or enabling multi-pack per step in a future change)
  - [x] Refactor `_prepare_batch_inputs` (or add helpers) to return:
    - [x] packed training batch (`bsz=1`) created from selected segments via `template.padding_free=True`
    - [x] `_rollout_matching_meta` list aligned to packed segment order, with `encoded_len` per segment
- [x] 1.4 Update `compute_loss` in `src/trainers/rollout_matching_sft.py`:
  - [x] Support packed-mode indexing (one packed row containing multiple sample segments)
  - [x] Keep un-packed behavior unchanged
- [x] 1.5 Tests:
  - [x] Add synthetic packed-mode tests to `tests/test_rollout_matching_sft.py`:
    - [x] label mask equivalence (packed vs un-packed) for CE masking
    - [x] coord supervision index offset correctness
    - [x] prompt prefix sanity check still works under packing
- [x] 1.6 Docs + configs:
  - [x] Update `configs/rollout_matching_sft_template.yaml` with the new knobs and recommended defaults
  - [x] Update `docs/STAGE2_ROLLOUT_MATCHING_RUNBOOK.md` and `docs/PACKING_MODE_GUIDE.md` to reflect stage_2 packing support (or the chosen config semantics)
- [x] 1.7 Verification / profiling:
  - [x] Add lightweight timers around rollout/generate/parse/match/forward (rank-local)
  - [x] Run a 50-200 sample smoke and record:
    - [x] steps/sec (before/after)
    - [x] rollout time vs forward time split
    - [x] GPU utilization snapshot
  - Results (2026-01-17, HF backend, train_sample_limit=50, max_steps=5):
    - No-pack config: `temp/stage2_smoke/stage2_smoke_hf_nopack_50.yaml`
      - train_steps_per_second: 0.038 (runtime_s: 131.23)
      - mean time/rollout_generate_s: 21.35s; mean time/forward_s: 1.37s
      - GPU util sample: `output_debug/stage2_smoke_hf_nopack_50/nvidia_smi_20260117_141845.csv`
      - log: `output_debug/stage2_smoke_hf_nopack_50/stdout_20260117_141845.log`
    - Pack config: `temp/stage2_smoke/stage2_smoke_hf_pack_50.yaml`
      - train_steps_per_second: 0.041 (runtime_s: 123.26)
      - mean time/rollout_generate_s: 21.37s; mean time/forward_s: 0.93s; mean time/post_rollout_pack_s: 0.019s
      - GPU util sample: `output_debug/stage2_smoke_hf_pack_50/nvidia_smi_20260117_142211.csv`
      - log: `output_debug/stage2_smoke_hf_pack_50/stdout_20260117_142211.log`
