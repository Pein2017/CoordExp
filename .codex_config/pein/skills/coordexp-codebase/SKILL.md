---
name: coordexp-codebase
description: Navigate the CoordExp research codebase by routing to the right local docs, entrypoints, configs, and scripts while following YAML-first workflow and repo guardrails. Use when you need codebase orientation or to locate where to implement a change.
---

# CoordExp Codebase Navigation

Use local `docs/` as the source of truth. Do not duplicate docs content; link to it and read it when needed.
Before relying on the autogenerated docs index, you may run the updater once (it is idempotent).

## Docs Index (Source Of Truth)

<!-- AUTO_DOCS_INDEX:START -->
_Autogenerated from `docs/**/*.md` (paths + H1 titles only). Run `python3 "$CODEX_HOME/skills/coordexp-codebase/scripts/update_docs_index.py"` to refresh._

### Data + Datasets

- Fusion Dataset (Multi-JSONL Training): `docs/data/FUSION_DATASET.md`
- Data Preprocessing & Intake Pipeline: `docs/data/INTAKE_PIPELINE.md`
- Data JSONL Contract (Global): `docs/data/JSONL_CONTRACT.md`
- Packing Mode Guide (Default: 12k, eff_bs=12): `docs/data/PACKING.md`
- Data & Datasets: `docs/data/README.md`
- Visual Genome (VG) -> CoordExp JSONL: `docs/data/VISUAL_GENOME.md`

### Training + Repro

- Architecture (Logging & Reproducibility): `docs/ARCHITECTURE.md`
- Porting notes between Qwen3-VL and CoordExp: `docs/standards/PORTING.md`
- Upstream Dependencies: `docs/standards/UPSTREAM.md`
- Coord Objective & Adapter: `docs/training/COORD_OBJECTIVE_AND_ADAPTER.md`
- Training Metrics and Losses (Quick Reference): `docs/training/METRICS_LOSSES.md`
- Stage-2 Training Runbook (Rollout-Aligned + Two-Channel): `docs/training/STAGE2_RUNBOOK.md`

### Eval + Inference

- Detection Evaluator (CoordExp): `docs/eval/README.md`

### Other

- Documentation Index: `docs/README.md`
- draft: `docs/notes/patent/draft.md`
- Code & Architecture Style (Transformers-Inspired, Option A): `docs/standards/CODE_STYLE.md`
- Repo Hygiene Constitution (CoordExp): `docs/standards/REPO_HYGIENE.md`
<!-- AUTO_DOCS_INDEX:END -->

## Task Routing (What To Read First)

- Editing/adding a dataset -> start with `docs/data/README.md`, then `docs/data/JSONL_CONTRACT.md`, then `docs/data/INTAKE_PIPELINE.md`.
- Debugging a JSONL or geometry mismatch -> start with `docs/data/JSONL_CONTRACT.md` (and check `src/datasets/geometry.py`).
- Packing questions (speed/length/eff batch size) -> start with `docs/data/PACKING.md`.
- Loss/metric interpretation -> start with `docs/training/METRICS_LOSSES.md`.
- Logging + reproducibility artifacts -> start with `docs/ARCHITECTURE.md`.
- Detection eval behavior -> start with `docs/eval/README.md`.
- Inference pipeline behavior -> use the Docs Index section "Eval + Inference" (or `rg -n \"infer|pipeline\" docs`).
- Rollout matching -> start with `docs/training/STAGE2_RUNBOOK.md`.
- Stage-2 AB training (A/B schedule, server-mode topology, step-budgeted Channel-B) -> start with `docs/training/STAGE2_RUNBOOK.md`.

## Smoke Checks (Stage-2)

- Unit-level (no GPUs): `PYTHONPATH=. conda run -n ms python -m pytest -q tests/test_stage2_objective_atoms_projection.py`
- Config-contract (no GPUs): `PYTHONPATH=. conda run -n ms python -m pytest -q tests/test_stage2_ab_config_contract.py`
- Config materialization (fast, no GPUs; catches strict allowlist issues early):
  - `PYTHONPATH=. conda run -n ms python -c "from src.config.loader import ConfigLoader; ConfigLoader.load_materialized_training_config('configs/stage2_two_channel/base.yaml'); print('OK')"`
- Trainer smoke (requires GPUs + a local checkpoint; HF backend, 2 steps):
  - `bash scripts/train_stage2.sh gpus=0 config=configs/stage2_two_channel/smoke/ab_mixed_pipeline_explicit.yaml`
  - Verify `logging.jsonl` has `stage2/channel_a|stage2/channel_b` tags and that `time/rollout_generate_s > 0` on B-steps.

## Code Entry Points (When Implementing Changes)

- Training entrypoint: `src/sft.py`
- Config merge + prompt resolution: `src/config/loader.py` (prompts live in `src/config/prompts.py`)
- Datasets + geometry helpers: `src/datasets/` (geometry: `src/datasets/geometry.py`)
- Stage-2 trainers:
  - Two-channel (A/B schedule + Channel-B rollout teacher forcing): `src/trainers/stage2_two_channel.py`
  - Rollout-aligned (single-surface rollout teacher forcing): `src/trainers/stage2_rollout_aligned.py`
- Stage-2 pipeline allowlists + loss-atom projection: `src/trainers/teacher_forcing/module_registry.py`, `src/trainers/teacher_forcing/objective_atoms.py`
- Augmentation ops: `src/datasets/augmentation/ops.py`
- Eval/infer scripts: `scripts/evaluate_detection.py`, `scripts/run_infer.py`, `scripts/run_vis.sh`
- Experiment configs: `configs/`

## Codebase Index (Autogenerated)

<!-- AUTO_CODEBASE_INDEX:START -->
_Autogenerated from repo path scan (`src/`, `scripts/`, `configs/`). Run `python3 "$CODEX_HOME/skills/coordexp-codebase/scripts/update_docs_index.py"` to refresh._

### Core Pipeline

- Config merge + prompt resolution: `src/config/loader.py`
- Prompt templates: `src/config/prompts.py`
- Geometry helpers: `src/datasets/geometry.py`
- Detection evaluator: `src/eval/detection.py`
- Inference pipeline: `src/infer/pipeline.py`
- Training entrypoint: `src/sft.py`

### Trainer Modules

- `src/trainers/batch_extras.py`
- `src/trainers/final_checkpoint.py`
- `src/trainers/gkd_monitor.py`
- `src/trainers/rollout_matching_sft.py`
- `src/trainers/stage2_ab_training.py`
- `src/trainers/stage2_rollout_aligned.py`
- `src/trainers/stage2_two_channel.py`

### Dataset Modules

- `src/datasets/augment.py`
- Augmentation ops: `src/datasets/augmentation/ops.py`
- `src/datasets/collators.py`
- `src/datasets/contracts.py`
- `src/datasets/dense_caption.py`
- `src/datasets/fusion.py`
- `src/datasets/fusion_types.py`
- `src/datasets/unified_fusion_dataset.py`
- `src/datasets/utils.py`

### Runtime Scripts

- `scripts/analysis/report_rollout_stability.py`
- `scripts/analysis/rollout_backend_bench/benchmark_rollout_backends.py`
- `scripts/analysis/rollout_backend_bench/vis_rollout_backend_compare.py`
- `scripts/analysis/run_ckpt_pair_confidence_eval.sh`
- `scripts/analysis/visualize_packing_results.py`
- `scripts/evaluate_detection.py`
- `scripts/pipelines/run_rollout_stability_probe.sh`
- `scripts/run_infer.py`
- `scripts/run_infer_eval.sh`
- `scripts/run_vis.sh`
- `scripts/stage2_ab_server_train.sh`
- `scripts/tools/dump_rollout_text.py`
- `scripts/train.sh`
- `scripts/train_stage2.sh`

### Config Groups

- top-level config: `configs/base.yaml`
- 5 yaml files: `configs/bench/`
- top-level config: `configs/debug.yaml`
- 14 yaml files: `configs/dlora/`
- 1 yaml file: `configs/eval/`
- 3 yaml files: `configs/fusion/`
- 2 yaml files: `configs/infer/`
- 1 yaml file: `configs/postop/`
- 1 yaml file: `configs/public_data/`
- 15 yaml files: `configs/stage1/`
- 2 yaml files: `configs/stage2_rollout_aligned/`
- 19 yaml files: `configs/stage2_two_channel/`

### Source Module Roots

- 7 python files: `src/callbacks/`
- 11 python files: `src/common/`
- 8 python files: `src/config/`
- 6 python files: `src/coord_tokens/`
- 5 python files: `src/data_collators/`
- 29 python files: `src/datasets/`
- 5 python files: `src/eval/`
- 4 python files: `src/infer/`
- 7 python files: `src/metrics/`
- 2 python files: `src/optim/`
- 47 python files: `src/trainers/`
- 6 python files: `src/utils/`
<!-- AUTO_CODEBASE_INDEX:END -->

## YAML-First Config Workflow (Summary)

- CLI: `python -m src.sft --config <yaml> [--base_config <yaml>] [--debug|--verbose]`
- Inheritance: `extends`/`inherit`; cycles fail fast.
- Prompts:
  - Default: built-in prompts in `src/config/prompts.py`.
  - Optional override: set `custom.user_prompt: /path/to/prompt.txt` (or per-dataset `user_prompt` in fusion configs).
- Required keys (training contract):
  - `custom.json_format: standard` (required; typo-guard)
  - `custom.object_field_order: desc_first|geometry_first` (required; keep parity with `infer.object_field_order`)
  - `custom.emit_norm: none` (required; runtime normalization is disabled)
  - `custom.coord_tokens.enabled: true` and `custom.coord_tokens.skip_bbox_norm: true` (required; coords must already be norm1000)
  - Dataset source: either `custom.train_jsonl` / `custom.val_jsonl` (single-source) OR `custom.fusion_config` (multi-source; supported but less common)
- Summary/order: `custom.use_summary`; `custom.object_ordering: sorted|random`.
- Coord tokens: `custom.coord_tokens.enabled`; if JSONL already stores coord tokens, set `custom.coord_tokens.skip_bbox_norm: true`.
- KD guards: enabling GKD/visual KD requires `rlhf.teacher_model`; teacher/student vocab sizes must match.
- Packing: see `docs/data/PACKING.md` for defaults; `effective_batch_size` is used to derive accumulation steps.

## Training Guardrails (Implementation Notes)

- Ensure `sft.prepare_model(...)` runs before trainer (entrypoint does this); otherwise full weights may train/save.
- Coord-offset adapter: enable via `custom.coord_offset`; ids must fit tokenizer vocab; module added to `modules_to_save` and hooks reattach after PEFT wrap.
- Fusion (supported but less common): `custom.fusion_config` overrides `custom.train_jsonl`/`custom.val_jsonl`.
  - Prefer offline JSONL merge when possible.
  - Stage-1 dataset-level packing is not supported for fusion datasets; disable `training.packing` for fusion runs (see `docs/data/FUSION_DATASET.md` and `docs/data/PACKING.md`).
- Packing: consult `docs/data/PACKING.md` for the current (strict) implementation guardrails (static packing mode; template requirements; fusion constraints).
- Save-delay: `training.save_delay_steps|epochs` or `save_delay_config` blocks checkpoints until the delay passes.
- Debugging: `--debug` dumps conversation text + image token counts; `custom.dump_conversation_text` writes to `output_dir`.

## Navigation Workflow (Fast + Reproducible)

1. Read the relevant `docs/*.md` first for contract/intent.
2. Use `rg` for initial discovery; use Serena MCP for symbol-aware edits.
3. Prefer YAML knobs/configs over new CLI flags; keep runs reproducible (seed + config + logged outputs).

## Keeping This Skill Updated (Local)

- One-shot refresh: `python3 "$CODEX_HOME/skills/coordexp-codebase/scripts/update_docs_index.py"`
- Watch `docs/`, `src/`, `scripts/`, and `configs/` for changes (foreground): `python3 "$CODEX_HOME/skills/coordexp-codebase/scripts/watch_docs_index.py"`
