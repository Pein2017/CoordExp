# Production Stage-2 AB ablation base: LVIS bbox-only max60 from ckpt-1516 (merged),
# vLLM server mode, DoRA ("dlora"), and num_train_epochs=2.
#
# This file is meant to be extended by schedule variants so that only the
# stage2_ab schedule changes across runs (A-only / B-only / AB-mixed).
extends: ../rollout_matching_sft_template.yaml

# Learner packing length cap (prompt + response + image tokens). One packed sequence per backward.
global_max_length: 12000

model:
  model: output/1-26/checkpoint-1516-merged

tuner:
  train_type: lora
  use_swift_lora: false
  use_dora: true
  freeze_llm: false
  freeze_vit: false
  freeze_aligner: false
  target_modules: [all-linear]
  target_regex: null
  modules_to_save: []
  lora_rank: 16
  lora_alpha: 32
  lora_dropout: 0.0
  lora_bias: none

deepspeed:
  enabled: false

training:
  # Variants should override output_dir/logging_dir to avoid clobbering checkpoints.
  output_dir: output/stage2_ab/prod_bbox_max60_ckpt1516_ablation_ep2
  logging_dir: tb/stage2_ab/prod_bbox_max60_ckpt1516_ablation_ep2

  num_train_epochs: 2
  # GPU memory constraint: one packed sequence per backward.
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1

  # Auto-computes gradient_accumulation_steps based on world_size:
  # effective_batch_size = per_device_train_batch_size * world_size * grad_accum
  effective_batch_size: 32
  # Required for Channel-B step mode to avoid partial accumulation windows.
  dataloader_drop_last: true

  # Dense logging for apples-to-apples throughput + stability comparison.
  logging_steps: 10
  logging_first_step: true

  # Stage-2 AB already logs core rollout/matching metrics on B steps.
  eval_strategy: "steps"
  eval_steps: 80

  save_strategy: "steps"
  save_steps: 200
  save_total_limit: 2
  save_delay_steps: 100

  optimizer: multimodal
  learning_rate: 2.0e-5
  vit_lr: 2.0e-5
  aligner_lr: 5.0e-5
  weight_decay: 0.1

stage2_ab:
  schedule:
    # Channel-B should be sparse (~5%) to stay a cold path.
    b_ratio: 0.05
  n_softctx_iter: 2
  desc_ce_weight: 1.0
  bbox_smoothl1_weight: 2.0
  bbox_ciou_weight: 1.0
  softctx_temperature: 1.0
  # Channel-B rollout refactor: async actor-learner (server rollouts, queue-gated).
  channel_b:
    # 'async' is the recommended mode for vLLM server rollouts and multi-GPU learners:
    # - per-rank ready-pack queues
    # - rank0 sync + step-kind broadcast (DDP safety)
    # - feasibility gate (fallback to A if queues are empty)
    mode: async
    async:
      # Rule of thumb: set prefetch_target_packs >= gradient_accumulation_steps (GAS),
      # and give extra slack so Channel-B feasibility rarely fails.
      #
      # With effective_batch_size=32 and per_device_train_batch_size=1:
      # - world_size=2  => GAS=16
      # - world_size=4  => GAS=8
      queue_limit: 64
      version_window: 8
      sync_every_steps: 4
      prefetch_target_packs: 32
    # (Legacy) step-budgeted + pipelined mode knobs are ignored in async mode.
    rollouts_per_step: null
    enable_pipeline: false
    rollout_decode_batch_size: 2
    # Reordered-GT SFT (B3/7.3): apply CE over a GT sequence arranged in predicted order.
    reordered_gt_sft: true
    # Downweight desc CE for matched objects only; keep missing-object recall learning strict.
    desc_ce_weight_matched: 0.2
    semantic_desc_gate:
      # Enabled by default, but revision MUST be pinned for reproducibility.
      enabled: true
      model_name_or_path: sentence-transformers/all-MiniLM-L6-v2
      threshold: 0.5
      revision: c9745ed1d9f207416be6d2e6f8de32d1f16199bf

custom:
  trainer_variant: stage2_ab_training

  # Full LVIS bbox-only coord-token JSONLs.
  train_jsonl: public_data/lvis/rescale_32_768_bbox_max60/train.bbox_only.max60.coord.jsonl
  val_jsonl: public_data/lvis/rescale_32_768_bbox_max60/val.bbox_only.max60.coord.jsonl

  # Full dataset (no smoke sampling caps).
  train_sample_limit: null
  val_sample_limit: null

  extra:
    rollout_matching:
      rollout_backend: vllm
      decode_mode: greedy
      max_new_tokens: 3084
      decoding:
        temperature: 0.0
        top_p: 1.0
        top_k: -1
      repetition_penalty: 1.08
      # Rollout request batching (client-side). With step-budgeted Channel-B, this should
      # typically match `stage2_ab.channel_b.rollout_decode_batch_size`.
      rollout_generate_batch_size: 1
      rollout_infer_batch_size: 2
      # For stage2-ab step-budgeted mode, packing happens inside the step; keep micro here.
      # Async actor-learner requires window-scope packing so each micro-step runs exactly
      # one packed forward/backward per rank (DDP safety).
      post_rollout_pack_scope: window

      vllm:
        mode: server
        # vLLM engine max_model_len for rollout (prompt + max_new_tokens). Keep this
        # much smaller than learner `global_max_length` for speed and KV-cache capacity.
        max_model_len: 12000
        # Full merged-weight sync is the robust default for multimodal models.
        # NOTE: vLLM LoRA enablement is not required for full sync.
        enable_lora: false
        sync:
          mode: full
          fallback_to_full: true
        server:
          timeout_s: 240.0
          # If null, the trainer defaults to timeout_s (never infinite).
          infer_timeout_s: null
          servers:
            - base_url: http://127.0.0.1:8000
              group_port: 51216
