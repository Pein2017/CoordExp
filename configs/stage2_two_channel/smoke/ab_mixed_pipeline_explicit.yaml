global_max_length: 12000

model:
  model: /data/CoordExp/output/stage1/coco_bbox_max60-coco80-desc_first/epoch_4-softce_w1-coco80-ckpt_1832-merged
  torch_dtype: bfloat16
  attn_impl: flash_attention_2

template:
  template: qwen3_vl
  truncation_strategy: raise
  max_pixels: 786432

tuner:
  train_type: lora
  use_swift_lora: false
  use_dora: true
  freeze_llm: false
  freeze_vit: false
  freeze_aligner: false
  target_modules: [all-linear]
  target_regex: null
  modules_to_save: []
  lora_rank: 16
  lora_alpha: 32
  lora_dropout: 0.0
  lora_bias: none

training:
  run_name: smoke_ab_mixed_pipeline_explicit
  output_dir: output/stage2_two_channel/smoke/ab_mixed_pipeline_explicit
  logging_dir: tb/stage2_two_channel/smoke/ab_mixed_pipeline_explicit
  gradient_checkpointing: true
  bf16: true
  report_to: [tensorboard]
  seed: 17
  warmup_ratio: 0.05
  max_grad_norm: 1.0
  add_version: true
  save_safetensors: true
  save_total_limit: 2
  save_last_epoch: true
  save_only_model: true
  logging_steps: 1
  logging_first_step: true
  num_train_epochs: 1
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 4
  effective_batch_size: 8
  dataloader_drop_last: true
  packing: true
  packing_buffer: 128
  packing_min_fill_ratio: 0.5
  packing_drop_last: true
  eval_packing: false
  metric_for_best_model: rollout/f1
  greater_is_better: true
  optimizer: multimodal
  learning_rate: 2.0e-5
  vit_lr: 2.0e-5
  aligner_lr: 5.0e-5
  weight_decay: 0.0
  eval_strategy: steps
  eval_steps: 1
  save_strategy: steps
  save_steps: 1
  save_delay_steps: 0
  max_steps: 2

data:
  dataset: [dummy]
  val_dataset: [dummy]
  dataset_num_proc: 1
  dataloader_num_workers: 0
  dataloader_pin_memory: false
  dataloader_prefetch_factor: null
  dataloader_persistent_workers: false

stage2_ab:
  schedule:
    b_ratio: 0.5
  n_softctx_iter: 2
  softctx_grad_mode: em_detach
  pipeline:
    objective:
      - name: token_ce
        enabled: true
        weight: 1.0
        channels: [A, B]
        config:
          desc_ce_weight: 1.0
          self_context_struct_ce_weight: 0.1
          rollout_fn_desc_weight: 1.0
          rollout_matched_prefix_struct_weight: 1.0
          rollout_drop_invalid_struct_ce_multiplier: 1.0
      - name: bbox_geo
        enabled: true
        weight: 1.0
        channels: [A, B]
        config:
          smoothl1_weight: 2.0
          ciou_weight: 0.5
      - name: coord_reg
        enabled: true
        weight: 1.0
        channels: [A, B]
        config:
          coord_ce_weight: 0.0
          coord_el1_weight: 0.0
          coord_ehuber_weight: 0.0
          coord_huber_delta: 0.001
          coord_entropy_weight: 0.0
          coord_gate_weight: 1.0
          text_gate_weight: 0.0
          soft_ce_weight: 0.02
          self_context_soft_ce_weight: 0.02
          w1_weight: 0.02
          temperature: 1.0
          target_sigma: 2.0
          target_truncate: null
    diagnostics:
      - name: coord_diag
        enabled: true
        weight: 1.0
        channels: [A, B]
        config: {}
  channel_b: {}

custom:
  trainer_variant: stage2_two_channel
  json_format: standard
  object_field_order: desc_first
  emit_norm: none
  train_jsonl: /data/CoordExp/public_data/coco/rescale_32_768_bbox_max60/train.coord.jsonl
  val_jsonl: /data/CoordExp/public_data/coco/rescale_32_768_bbox_max60/val.coord.jsonl
  train_sample_limit: 64
  val_sample_limit: 16
  coord_tokens:
    enabled: true
    skip_bbox_norm: true
  extra:
    prompt_variant: coco_80

rollout_matching:
  rollout_backend: hf
  decode_batch_size: 2
  decode_mode: greedy
  max_new_tokens: 256
  decoding:
    temperature: 0.0
    top_p: 1.0
    top_k: -1
  repetition_penalty: 1.1
  candidate_top_k: 5
  maskiou_gate: 0.3
  maskiou_resolution: 256
  fp_cost: 0.5
  fn_cost: 2
  eval_detection:
    enabled: true
    metrics: coco
    use_segm: false
    strict_parse: true
    score_mode: constant
    constant_score: 1.0
    pred_score_source: eval_rollout_constant
    pred_score_version: 2
  ot_cost: l2
  ot_epsilon: 10
  ot_iters: 1
  monitor_dump:
    enabled: false
