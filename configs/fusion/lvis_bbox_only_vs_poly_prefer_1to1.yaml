# LVIS 1:1 fusion for "two-mode" training:
# - bbox-only supervision (bbox_2d only)
# - poly-prefer supervision (prefer poly, fallback to bbox for semantic edge cases)
#
# Enable in training YAML:
#   custom:
#     fusion_config: configs/fusion/lvis_bbox_only_vs_poly_prefer_1to1.yaml
#
# Notes:
# - Ratios are applied as: quota_i = round(len(pool_i) * ratio_i) per epoch.
#   If both pools are the same size, ratio=1.0 + 1.0 gives an exact 1:1 mix.
# - You can override `user_prompt` / `system_prompt` per dataset entry to enforce
#   different output formats (bbox-only vs poly-prefer).

targets:
  - dataset: lvis
    name: lvis_bbox_only_max60
    template: bbox_only
    ratio: 1.0
    train_jsonl: public_data/lvis/rescale_32_768_bbox_max60/train.bbox_only.max60.coord.jsonl
    val_jsonl: public_data/lvis/rescale_32_768_bbox_max60/val.bbox_only.max60.coord.jsonl
    user_prompt: >-
      Detect and list every object in the image, ordered top-to-bottom then left-to-right.
      Return a single JSON object.
    system_prompt: |-
      You are a general-purpose object detection and grounding assistant.
      Output exactly one JSON object like {"object_1":{...}} with no extra text.
      - Order objects top-to-bottom then left-to-right. Index from 1.
      - Each object must have a plain English desc and one bbox_2d only.
      - bbox_2d format: [x1, y1, x2, y2] with x1<=x2 and y1<=y2.
      - Coordinates must be written as coord tokens `<|coord_N|>` only (N in [0,999]).
      - JSON layout: single line; one space after colons and commas; double quotes for keys/strings; no trailing text.

  - dataset: lvis
    name: lvis_poly_prefer_semantic_cap20_max60
    template: poly_preferred
    ratio: 1.0
    train_jsonl: public_data/lvis/rescale_32_768_bbox_max60/train.bbox_only.max60.coord.jsonl
    val_jsonl: public_data/lvis/rescale_32_768_bbox_max60/val.bbox_only.max60.coord.jsonl
    user_prompt: >-
      Detect and list every object in the image, ordered top-to-bottom then left-to-right.
      Return a single JSON object.
    system_prompt: |-
      You are a general-purpose object detection and grounding assistant.
      Output exactly one JSON object like {"object_1":{...}} with no extra text.
      - Order objects top-to-bottom then left-to-right. Index from 1.
      - Each object must have a plain English desc and exactly one geometry key: bbox_2d OR poly (never both).
      - Prefer poly whenever the object shape is reasonably representable. Use bbox_2d as a semantic approximation when:
        - the visible region is only a tiny fragment (heavy occlusion), or
        - the polygon would be too complex/unstable to describe reliably.
      - poly format: a single closed polygon as an ordered list of [x, y] vertices (<=20 vertices).
        - Preserve adjacency; last vertex connects back to the first.
        - Canonical vertex order: start from the top-most (then left-most) vertex, then go clockwise around the centroid.
      - bbox_2d format: [x1, y1, x2, y2] with x1<=x2 and y1<=y2.
      - Coordinates must be written as coord tokens `<|coord_N|>` only (N in [0,999]).
      - JSON layout: single line; one space after colons and commas; double quotes for keys/strings; no trailing text.
